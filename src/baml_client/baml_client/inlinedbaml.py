###############################################################################
#
#  Welcome to Baml! To use this generated code, please run the following:
#
#  $ pip install baml-py
#
###############################################################################

# This file was generated by BAML: please do not edit it. Instead, edit the
# BAML files and re-generate this code.
#
# ruff: noqa: E501,F401
# flake8: noqa: E501,F401
# pylint: disable=unused-import,line-too-long
# fmt: off

file_map = {
    
    "clients.baml": "// Learn more about clients at https://docs.boundaryml.com/docs/snippets/clients/overview\n\nclient<llm> CustomGPT4o {\n  provider openai\n  options {\n    model \"gpt-4o\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomGPT4oMini {\n  provider openai\n  retry_policy Exponential\n  options {\n    model \"gpt-4o-mini\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomSonnet {\n  provider anthropic\n  options {\n    model \"claude-3-5-sonnet-20241022\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\n\nclient<llm> CustomHaiku {\n  provider anthropic\n  retry_policy Constant\n  options {\n    model \"claude-3-haiku-20240307\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/round-robin\nclient<llm> CustomFast {\n  provider round-robin\n  options {\n    // This will alternate between the two clients\n    strategy [CustomGPT4oMini, CustomHaiku]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/fallback\nclient<llm> OpenaiFallback {\n  provider fallback\n  options {\n    // This will try the clients in order until one succeeds\n    strategy [CustomGPT4oMini, CustomGPT4oMini]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/retry\nretry_policy Constant {\n  max_retries 3\n  // Strategy is optional\n  strategy {\n    type constant_delay\n    delay_ms 200\n  }\n}\n\nretry_policy Exponential {\n  max_retries 2\n  // Strategy is optional\n  strategy {\n    type exponential_backoff\n    delay_ms 300\n    multiplier 1.5\n    max_delay_ms 10000\n  }\n}\n",
    "generators.baml": "// This helps use auto generate libraries you can use in the language of\n// your choice. You can have multiple generators if you use multiple languages.\n// Just ensure that the output_dir is different for each generator.\ngenerator target {\n    // Valid values: \"python/pydantic\", \"typescript\", \"ruby/sorbet\", \"rest/openapi\"\n    output_type \"python/pydantic\"\n\n    // Where the generated code will be saved (relative to baml_src/)\n    output_dir \"../src/baml_client\"\n\n    // The version of the BAML package you have installed (e.g. same version as your baml-py or @boundaryml/baml).\n    // The BAML VSCode extension version should also match this version.\n    version \"0.89.0\"\n\n    // Valid values: \"sync\", \"async\"\n    // This controls what `b.FunctionName()` will be (sync or async).\n    default_client_mode sync\n}\n",
    "main.baml": "// BAML Configuration for Python Package Documentation Agent\n\n// Data Models\nclass PackageInfo {\n  name string\n  version string\n  description string?\n  docs_url string?\n  repo_url string?\n  is_deprecated bool\n  deprecated_methods string[]\n  alternative_packages string[]\n}\n\nclass EfficiencyComparison {\n  package_name string\n  alternatives PackageAlternative[]\n  recommendation string\n  performance_notes string[]\n  lambda_compatibility bool\n}\n\nclass PackageAlternative {\n  name string\n  performance_score float // 0-10 scale\n  lambda_size_mb float\n  pros string[]\n  cons string[]\n  use_cases string[]\n}\n\nclass DeprecationAnalysis {\n  package_name string\n  method_name string\n  is_deprecated bool\n  deprecation_version string?\n  removal_version string?\n  alternatives string[]\n  migration_notes string[]\n}\n\nclass CodeAnalysisResult {\n  packages_detected string[]\n  trigger_reasons string[]\n  recommendations CodeRecommendation[]\n  lambda_optimizations string[]\n}\n\nclass CodeRecommendation {\n  type string // \"package_upgrade\", \"method_replacement\", \"optimization\"\n  current_code string\n  suggested_code string\n  reason string\n  confidence_score float\n}\n\n// Multi-Agent System Classes\n\nclass PipelineAnalysisResult {\n  current_pattern string\n  functions_detected PipelineFunction[]\n  complexity_score float\n  migration_feasibility string\n  estimated_effort_hours int\n  aws_service_recommendations string[]\n  business_logic BusinessLogic\n  dependencies string[]\n  data_flow DataFlow[]\n}\n\nclass PipelineFunction {\n  name string\n  line_count int\n  arguments string[]\n  has_async bool\n  has_decorators bool\n  decorators string[]\n  calls_external_apis bool\n  file_operations bool\n  database_operations bool\n  data_transformations bool\n}\n\nclass BusinessLogic {\n  data_sources string[]\n  transformations string[]\n  outputs string[]\n  business_rules string[]\n  error_handling ErrorHandling\n  configuration string[]\n}\n\nclass ErrorHandling {\n  has_try_catch bool\n  exception_types string[]\n  logging_present bool\n}\n\nclass DataFlow {\n  type string\n  target string\n  source string\n  line_number int\n}\n\nclass ArchitectureDecision {\n  primary_service string\n  supporting_services string[]\n  pattern string\n  splitter_node string\n  rationale string\n  estimated_performance_improvement string\n  estimated_cost_reduction string\n  scalability string\n  splitter_analysis SplitterAnalysis\n}\n\nclass SplitterAnalysis {\n  optimal_split_point string\n  split_rationale string\n  pipeline_stages_analysis PipelineStageAnalysis[]\n  performance_impact PerformanceEstimate\n  cost_impact CostEstimate\n}\n\nclass PipelineStageAnalysis {\n  stage_name string\n  complexity string\n  runtime_estimate string\n  parallelization_benefit string\n  bottleneck_potential string\n  split_justification string?\n}\n\nclass PerformanceEstimate {\n  improvement_percentage float\n  bottleneck_reduction string\n  scalability_factor float\n}\n\nclass CostEstimate {\n  reduction_percentage float\n  monthly_savings_usd float\n  cost_factors string[]\n}\n\nclass TransformationRequest {\n  pipeline_code string\n  business_requirements string\n  target_platform string\n  performance_goals string // JSON string\n}\n\nclass TransformationResult {\n  success bool\n  transformed_code string\n  validation_results string // JSON string\n  infrastructure_code string\n  git_workflow_results string // JSON string\n}\n\nclass AgentDecision {\n  agent_name string\n  decision string\n  confidence float\n  reasoning string\n  outputs string // JSON string\n}\n\nclass ConflictResolution {\n  conflicting_agents string[]\n  conflict_description string\n  proposed_solutions string[]\n  final_decision string\n  confidence_score float\n}\n\nclass ValidationResult {\n  functional_equivalence bool\n  performance_maintained bool\n  security_validated bool\n  test_coverage_adequate bool\n  issues_found string[]\n}\n\nclass CustomRepoInfo {\n  repo_name string\n  functions_available string[]\n  classes_available string[]\n  latest_version string\n  documentation_url string?\n}\n\n// LLM Client Configuration\nclient GPT4 {\n  provider openai\n  options {\n    model gpt-4-turbo-preview\n    temperature 0.1\n    max_tokens 2000\n  }\n}\n\nclient ClaudeHaiku {\n  provider anthropic\n  options {\n    model claude-3-haiku-20240307\n    temperature 0.1\n    max_tokens 1500\n  }\n}\n\n// Core Functions\n\nfunction AnalyzeCodeForTriggers(code: string, context: string) -> CodeAnalysisResult {\n  client GPT4\n\n  prompt #\"\n    You are an expert Python developer analyzing code for data pipeline optimization.\n\n    Analyze the following code and determine if documentation lookup is needed:\n\n    Code:\n    ```python\n    {{ code }}\n    ```\n\n    Context: {{ context }}\n\n    Look for:\n    1. Package imports that might need efficiency analysis\n    2. Methods that could be deprecated\n    3. AWS Lambda optimization opportunities\n    4. References to custom repositories\n\n    {{ ctx.output_format }}\n  \"#\n}\n\nfunction ComparePackageEfficiency(package_name: string, use_case: string) -> EfficiencyComparison {\n  client GPT4\n\n  prompt #\"\n    Compare the efficiency of {{ package_name }} for {{ use_case }} in AWS Lambda environment.\n\n    Consider:\n    - Performance benchmarks\n    - Memory usage\n    - Cold start impact\n    - Package size\n    - Popular alternatives (e.g., polars vs pandas, httpx vs requests, selectolax vs bs4)\n\n    Provide specific recommendations for AWS Lambda deployment.\n\n    {{ ctx.output_format }}\n  \"#\n}\n\nfunction CheckDeprecation(package_name: string, method_name: string) -> DeprecationAnalysis {\n  client ClaudeHaiku\n\n  prompt #\"\n    Check if {{ method_name }} in {{ package_name }} is deprecated or will be deprecated soon.\n\n    Provide:\n    - Current deprecation status\n    - Timeline for removal\n    - Alternative methods/approaches\n    - Migration guidance\n\n    {{ ctx.output_format }}\n  \"#\n}\n\nfunction GenerateCodeRecommendations(\n  analysis: CodeAnalysisResult,\n  package_info: PackageInfo[],\n  efficiency_data: EfficiencyComparison[]\n) -> CodeRecommendation[] {\n  client GPT4\n\n  prompt #\"\n    Based on the analysis and package information, generate specific code recommendations.\n\n    Analysis: {{ analysis }}\n    Package Info: {{ package_info }}\n    Efficiency Data: {{ efficiency_data }}\n\n    Generate actionable recommendations with:\n    - Specific code changes\n    - Reasoning for each recommendation\n    - Confidence scores\n    - AWS Lambda optimizations\n\n    {{ ctx.output_format }}\n  \"#\n}\n\n// Pipeline Modernization CLI Functions\n\nclass PipelineIssue {\n  description string\n  severity string // \"low\", \"medium\", \"high\", \"critical\"\n  line_number int?\n}\n\nclass PipelineRecommendation {\n  description string\n  impact string // \"performance\", \"cost\", \"maintainability\", \"security\"\n  effort string // \"low\", \"medium\", \"high\"\n}\n\nclass SplittingOpportunity {\n  location string\n  reason string\n  benefit string\n}\n\nclass PipelineAnalysis {\n  complexity_score int // 1-10 scale\n  current_pattern string\n  modernization_potential string // \"Low\", \"Medium\", \"High\"\n  performance_improvement int // percentage\n  cost_savings int // estimated USD\n  estimated_effort int // hours\n  issues PipelineIssue[]\n  recommendations PipelineRecommendation[]\n  splitting_opportunities SplittingOpportunity[]\n}\n\nclass PipelineTransformation {\n  modernized_code string\n  architecture_pattern string\n  improvements string[]\n  deployment_notes string[]\n}\n\nfunction AnalyzePipeline(code: string) -> PipelineAnalysis {\n  client GPT4\n  prompt #\"\n    You are an expert Python data pipeline analyst. Analyze the following pipeline code for modernization opportunities.\n\n    Code to analyze:\n    ```python\n    {{ code }}\n    ```\n\n    Perform a comprehensive analysis covering:\n\n    1. **Complexity Assessment** (1-10 scale):\n       - Code structure and organization\n       - Function size and responsibility distribution\n       - Error handling patterns\n       - Async/await usage\n\n    2. **Current Architecture Pattern**:\n       - Identify if it follows Prepare-Fetch-Transform-Save, ETL, monolithic, or other patterns\n       - Assess modularity and separation of concerns\n\n    3. **Issues Identification**:\n       - Performance bottlenecks\n       - Missing error handling\n       - Synchronous operations that could be async\n       - Memory usage problems\n       - Security concerns\n\n    4. **Modernization Potential**:\n       - How much benefit modernization would provide\n       - Feasibility of implementing modern patterns\n\n    5. **Performance & Cost Impact**:\n       - Estimated performance improvement percentage\n       - Projected cost savings in USD\n       - Implementation effort in hours\n\n    6. **Splitting Opportunities**:\n       - Where the pipeline could be split for parallelization\n       - Benefits of each potential split point\n       - AWS Lambda optimization opportunities\n\n    Focus on practical, actionable insights that directly improve pipeline performance and maintainability.\n\n    {{ ctx.output_format }}\n  \"#\n}\n\nfunction TransformPipeline(code: string, target_platform: string, analysis_context: string) -> PipelineTransformation {\n  client GPT4\n  prompt #\"\n    You are an expert Python architect specializing in pipeline modernization and AWS deployment.\n\n    Transform this legacy pipeline code into a modern, scalable implementation:\n\n    **Original Code:**\n    ```python\n    {{ code }}\n    ```\n\n    **Target Platform:** {{ target_platform }}\n    **Analysis Context:** {{ analysis_context }}\n\n    **Transformation Requirements:**\n\n    1. **Architecture Pattern**: Implement Prepare-Fetch-Transform-Save pattern\n    2. **Modern Python**: Use async/await, proper error handling, type hints\n    3. **AWS Integration**: Optimize for {{ target_platform }} deployment\n    4. **Performance**: Implement parallel processing where beneficial\n    5. **Observability**: Add structured logging and monitoring\n    6. **Error Handling**: Comprehensive exception handling with retries\n\n    **Code Structure:**\n    - Separate classes/functions for each stage (Prepare, Fetch, Transform, Save)\n    - Proper dependency injection and configuration management\n    - Clean separation of business logic from infrastructure concerns\n    - Type hints and docstrings throughout\n\n    **AWS Lambda Optimizations** (if target_platform is aws-lambda):\n    - Memory-efficient code patterns\n    - Minimal cold start overhead\n    - Proper resource cleanup\n    - Environment variable configuration\n    - CloudWatch integration\n\n    **Generate:**\n    1. Complete modernized Python code\n    2. Architecture pattern explanation\n    3. List of key improvements made\n    4. Deployment considerations\n\n    The code should be production-ready and follow Python best practices.\n\n    {{ ctx.output_format }}\n  \"#\n}\n\n// Multi-Agent System Functions\n\nfunction AnalyzePipelineStructure(code: string, context: string) -> PipelineAnalysisResult {\n  client GPT4\n  prompt #\"\n    Analyze this data pipeline code for modernization potential:\n\n    Code: {{ code }}\n    Context: {{ context }}\n\n    Identify:\n    1. Current architectural pattern (prepare-fetch-transform-save, ETL, monolithic, etc.)\n    2. Function breakdown and responsibilities\n    3. Complexity assessment (1-10 scale)\n    4. Feasibility for Prepare-Fetch-Transform-Save migration\n    5. Estimated effort in hours\n    6. Recommended AWS services (Lambda/Batch/Step Functions)\n    7. Business logic extraction\n    8. Data flow analysis\n    9. Dependencies and external integrations\n\n    Focus on understanding the pipeline's structure and modernization requirements.\n\n    {{ ctx.output_format }}\n  \"#\n}\n\nfunction OptimizeArchitecture(\n  pipeline_code: string,\n  business_requirements: string,\n  performance_targets: string,\n  cost_constraints: string\n) -> ArchitectureDecision {\n  client GPT4\n\n  prompt #\"\n    You are an expert AWS solutions architect specializing in data pipeline optimization.\n\n    Analyze this pipeline and determine the optimal AWS architecture:\n\n    Pipeline Code: {{ pipeline_code }}\n    Business Requirements: {{ business_requirements }}\n    Performance Targets: {{ performance_targets }}\n    Cost Constraints: {{ cost_constraints }}\n\n    Your analysis must include:\n\n    1. **Service Selection**: Choose between Lambda, Batch, ECS, Step Functions\n    2. **Architecture Pattern**: Monolithic, splitter, fan-out, or stream processing\n    3. **Splitter Analysis**: Determine optimal split point if applicable\n    4. **Performance Impact**: Quantified improvement estimates\n    5. **Cost Impact**: Expected cost reduction percentage\n    6. **Scalability Strategy**: How the solution scales with load\n\n    **Critical Decision Points:**\n    - Lambda is ideal for: <15min runtime, burst traffic, event-driven processing\n    - Batch is ideal for: >15min runtime, predictable workloads, cost optimization\n    - Step Functions for: Complex workflows, error handling, state management\n    - Splitter patterns for: Parallelizable workloads, I/O bound operations\n\n    **Splitter Node Selection:**\n    The splitter_node should be one of: 'prepare', 'fetch', 'transform', 'save'\n    Choose based on where the bottleneck occurs and where parallelization helps most.\n\n    Provide specific rationale that explains:\n    - WHY this architecture was chosen over alternatives\n    - WHERE the performance gains come from\n    - HOW costs are reduced through right-sizing\n\n    {{ ctx.output_format }}\n  \"#\n}\n\nfunction AnalyzeSplitterOptimization(\n  pipeline_code: string,\n  business_requirements: string,\n  performance_constraints: string\n) -> SplitterAnalysis {\n  client GPT4\n\n  prompt #\"\n    You are an expert AWS architect specializing in data pipeline optimization.\n\n    Analyze this pipeline code for optimal parallelization strategy:\n    {{ pipeline_code }}\n\n    Business requirements: {{ business_requirements }}\n    Performance constraints: {{ performance_constraints }}\n\n    For EACH stage in the Prepare-Fetch-Transform-Save pattern, analyze:\n    1. **Complexity**: Low/Medium/High based on computational requirements\n    2. **Runtime estimate**: Expected execution time (sequential vs parallel)\n    3. **Parallelization benefit**: How much the stage benefits from parallel processing\n    4. **Bottleneck potential**: Network I/O, CPU-bound, memory-bound, or none\n    5. **Split justification**: WHY this stage should or shouldn't be the split point\n\n    Determine the OPTIMAL split point where parallelization provides maximum efficiency gain.\n\n    CRITICAL: The split should happen AT THE STAGE LEVEL, not within a stage function.\n    Valid split points are: 'prepare', 'fetch', 'transform', 'save'\n\n    Focus on identifying the TRUE bottleneck - usually I/O bound operations like:\n    - Multiple HTTP requests (fetch stage)\n    - File processing operations\n    - Database operations\n\n    Provide clear rationale based on:\n    - Where most time is spent\n    - What scales best horizontally\n    - AWS Lambda execution model efficiency\n\n    {{ ctx.output_format }}\n  \"#\n}\n\nfunction CoordinateTransformation(\n  agent_outputs: string,\n  conflicts: string,\n  business_requirements: string\n) -> ConflictResolution {\n  client GPT4\n\n  prompt #\"\n    You are the Master Orchestrator coordinating multiple specialized agents.\n\n    Agent Outputs: {{ agent_outputs }}\n    Detected Conflicts: {{ conflicts }}\n    Business Requirements: {{ business_requirements }}\n\n    Analyze conflicts between agent recommendations and provide resolution:\n\n    1. **Identify Conflicting Decisions**: Which agents disagree and why\n    2. **Assess Business Impact**: How conflicts affect business requirements\n    3. **Propose Solutions**: Concrete steps to resolve conflicts\n    4. **Final Decision**: Authoritative resolution with confidence score\n\n    Consider:\n    - Priority of business requirements\n    - Technical feasibility of each recommendation\n    - Risk mitigation strategies\n    - Performance vs cost trade-offs\n\n    {{ ctx.output_format }}\n  \"#\n}\n\nfunction ResolveConflicts(\n  validation_results: string,\n  agent_outputs: string,\n  business_requirements: string\n) -> ConflictResolution {\n  client GPT4\n\n  prompt #\"\n    Resolve conflicts detected during validation phase.\n\n    Validation Results: {{ validation_results }}\n    Agent Outputs: {{ agent_outputs }}\n    Business Requirements: {{ business_requirements }}\n\n    Provide conflict resolution strategy including:\n    1. Root cause analysis of validation failures\n    2. Agent recommendation conflicts\n    3. Recommended retry strategies\n    4. Alternative approaches if initial plan fails\n\n    {{ ctx.output_format }}\n  \"#\n}\n\nfunction ValidateStrategy(\n  transformation_plan: string,\n  business_requirements: string,\n  risk_tolerance: string\n) -> ValidationResult {\n  client GPT4\n\n  prompt #\"\n    Validate the overall transformation strategy before execution.\n\n    Transformation Plan: {{ transformation_plan }}\n    Business Requirements: {{ business_requirements }}\n    Risk Tolerance: {{ risk_tolerance }}\n\n    Validate:\n    1. **Feasibility**: Can this plan be executed successfully?\n    2. **Risk Assessment**: What are the potential failure points?\n    3. **Business Alignment**: Does this meet business requirements?\n    4. **Resource Requirements**: Are resource estimates realistic?\n    5. **Timeline Validation**: Is the timeline achievable?\n\n    Provide go/no-go recommendation with detailed reasoning.\n\n    {{ ctx.output_format }}\n  \"#\n}\n\n// VS Code Chat Assistant Functions\n\nclass ChatMessage {\n  type string // \"user\", \"assistant\", \"system\"\n  content string\n  timestamp string\n}\n\nclass ChatContext {\n  userMessage string\n  conversationHistory ChatMessage[]\n  currentFileContext FileContext?\n  workspaceContext WorkspaceContext\n}\n\nclass FileContext {\n  fileName string\n  language string\n  content string\n  analysisResults AnalysisResults?\n}\n\nclass WorkspaceContext {\n  pythonFiles string[]\n  recentAnalyses AnalysisResults[]\n  projectType string?\n}\n\nclass AnalysisResults {\n  currentPattern string\n  complexityScore float\n  performanceImprovement string\n  costSavings string\n  awsServices string[]\n  feasibility string\n}\n\nclass ChatResponse {\n  intent string // \"analyze\", \"transform\", \"explain\", \"help\", \"general\"\n  confidence float\n  content string\n  suggestedActions string[]\n  followUpQuestions string[]\n  requiresFileAccess bool\n  recommendedCommands string[]\n}\n\nfunction ProcessChatMessage(context: ChatContext) -> ChatResponse {\n  client GPT4\n\n  prompt #\"\n    You are an expert AI assistant specializing in Python pipeline modernization.\n    You help developers transform legacy pipelines into modern, scalable architectures.\n\n    **User Message:** {{ context.userMessage }}\n\n    **Conversation History:**\n    {% for msg in context.conversationHistory %}\n    {{ msg.type }}: {{ msg.content }}\n    {% endfor %}\n\n    **Current File Context:**\n    {% if context.currentFileContext %}\n    File: {{ context.currentFileContext.fileName }}\n    Language: {{ context.currentFileContext.language }}\n    {% if context.currentFileContext.analysisResults %}\n    Previous Analysis:\n    - Pattern: {{ context.currentFileContext.analysisResults.currentPattern }}\n    - Complexity: {{ context.currentFileContext.analysisResults.complexityScore }}/10\n    - Potential: {{ context.currentFileContext.analysisResults.performanceImprovement }}\n    {% endif %}\n    {% else %}\n    No file currently open\n    {% endif %}\n\n    **Workspace Context:**\n    Python files: {{ context.workspaceContext.pythonFiles }}\n    Recent analyses: {{ context.workspaceContext.recentAnalyses | length }}\n\n    **Your Expertise:**\n    - Multi-agent pipeline transformation system\n    - AWS architecture optimization (Lambda, Step Functions, Batch)\n    - Prepare-Fetch-Transform-Save pattern implementation\n    - Package modernization (httpx, polars, orjson)\n    - Splitter pattern for parallel processing\n    - Infrastructure as Code (Terraform)\n    - Automated Git workflows and PR management\n\n    **Response Guidelines:**\n    1. Be helpful, friendly, and technical when appropriate\n    2. Provide specific, actionable recommendations\n    3. Reference the user's current file when relevant\n    4. Suggest concrete next steps\n    5. Explain complex concepts clearly\n    6. Offer to perform actions (analyze, transform, explain)\n\n    **Intent Classification:**\n    - \"analyze\": User wants code analysis or recommendations\n    - \"transform\": User wants to modernize/transform their code\n    - \"explain\": User wants explanations about patterns, decisions, or concepts\n    - \"help\": User needs general help or doesn't know what to ask\n    - \"general\": Conversational or informational questions\n\n    **Suggested Actions (choose relevant ones):**\n    - \"analyze_file\": Analyze the current file\n    - \"transform_pipeline\": Transform code to modern pattern\n    - \"preview_changes\": Show transformation preview\n    - \"create_pr\": Create pull request with changes\n    - \"explain_architecture\": Explain architectural decisions\n    - \"show_examples\": Provide code examples\n    - \"view_dashboard\": Open modernization dashboard\n\n    Generate a helpful, contextual response that addresses the user's needs.\n\n    {{ ctx.output_format }}\n  \"#\n}\n\nfunction GenerateCodeExplanation(\n  code: string,\n  question: string,\n  context: string\n) -> ChatResponse {\n  client GPT4\n\n  prompt #\"\n    You are explaining code to a developer who wants to understand pipeline modernization.\n\n    **Code to Explain:**\n    ```python\n    {{ code }}\n    ```\n\n    **User's Question:** {{ question }}\n    **Context:** {{ context }}\n\n    **Explain:**\n    1. What the current code does\n    2. Why modernization would help\n    3. Specific improvements possible\n    4. AWS architecture recommendations\n    5. Performance and cost benefits\n\n    Be technical but clear. Use examples and comparisons.\n    Focus on practical benefits the developer will see.\n\n    {{ ctx.output_format }}\n  \"#\n}\n\nfunction SuggestNextSteps(\n  currentState: string,\n  userGoals: string,\n  fileContext: FileContext?\n) -> ChatResponse {\n  client GPT4\n\n  prompt #\"\n    Based on the current state and user goals, suggest the best next steps.\n\n    **Current State:** {{ currentState }}\n    **User Goals:** {{ userGoals }}\n    **File Context:**\n    {% if fileContext %}\n    File: {{ fileContext.fileName }}\n    Analysis: {{ fileContext.analysisResults }}\n    {% else %}\n    No file context available\n    {% endif %}\n\n    Provide a prioritized action plan with:\n    1. Immediate next steps (what to do right now)\n    2. Short-term goals (this session)\n    3. Longer-term improvements\n    4. Specific commands or actions to take\n\n    Be actionable and specific. Reference VS Code commands when helpful.\n\n    {{ ctx.output_format }}\n  \"#\n}\n\nfunction AnalyzeChatIntent(\n  message: string,\n  conversationHistory: ChatMessage[]\n) -> string {\n  client ClaudeHaiku\n\n  prompt #\"\n    Classify the user's intent from this message in a chat about pipeline modernization.\n\n    Message: \"{{ message }}\"\n\n    Recent conversation:\n    {% for msg in conversationHistory %}\n    {{ msg.content }}\n    {% endfor %}\n\n    Return one of these intents:\n    - analyze: wants code analysis or recommendations\n    - transform: wants to modernize/change code\n    - explain: wants explanations or understanding\n    - help: needs general assistance\n    - general: conversational or other\n\n    Return only the intent word.\n  \"#\n}\n\n// Test Cases\n\ntest TestCodeAnalysis {\n  functions [AnalyzeCodeForTriggers]\n  args {\n    code \"import pandas as pd\\nimport requests\\ndf = pd.read_csv('data.csv')\\nresponse = requests.get('https://api.example.com')\"\n    context \"AWS Lambda data processing pipeline\"\n  }\n}\n\ntest TestEfficiencyComparison {\n  functions [ComparePackageEfficiency]\n  args {\n    package_name \"pandas\"\n    use_case \"CSV processing in AWS Lambda\"\n  }\n}\n\ntest TestDeprecationCheck {\n  functions [CheckDeprecation]\n  args {\n    package_name \"requests\"\n    method_name \"get\"\n  }\n}\n",
    "resume.baml": "// Defining a data model.\nclass Resume {\n  name string\n  email string\n  experience string[]\n  skills string[]\n}\n\n// Create a function to extract the resume from a string.\nfunction ExtractResume(resume: string) -> Resume {\n  // Specify a client as provider/model-name\n  // you can use custom LLM params with a custom client name from clients.baml like \"client CustomHaiku\"\n  client \"openai/gpt-4o\" // Set OPENAI_API_KEY to use this client.\n  prompt #\"\n    Extract from this content:\n    {{ resume }}\n\n    {{ ctx.output_format }}\n  \"#\n}\n\n\n\n// Test the function with a sample resume. Open the VSCode playground to run this.\ntest vaibhav_resume {\n  functions [ExtractResume]\n  args {\n    resume #\"\n      Vaibhav Gupta\n      vbv@boundaryml.com\n\n      Experience:\n      - Founder at BoundaryML\n      - CV Engineer at Google\n      - CV Engineer at Microsoft\n\n      Skills:\n      - Rust\n      - C++\n    \"#\n  }\n}\n",
}

def get_baml_files():
    return file_map